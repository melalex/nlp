{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jigsaw Unintended Bias in Toxicity Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    DataCollatorWithPadding,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    pipeline,\n",
    ")\n",
    "\n",
    "from src.data.kaggle import submit_competition\n",
    "from src.model.metrics import compute_metrics\n",
    "from src.data.toxicity import (\n",
    "    load_toxicity_dataset,\n",
    "    TOXICITY_LABEL_TO_ID,\n",
    "    TOXICITY_ID_TO_LABEL,\n",
    ")\n",
    "from src.util.torch_device import resolve_torch_device\n",
    "from src.definitions import MODELS_FOLDER, EXTERNAL_DATA_FOLDER, PROCESSED_DATA_FOLDER, SUBMITIONS_FOLDER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Prepare Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_seed = 42\n",
    "\n",
    "random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "device = resolve_torch_device()\n",
    "\n",
    "competition = \"jigsaw-unintended-bias-in-toxicity-classification\"\n",
    "submition_path = (\n",
    "    SUBMITIONS_FOLDER\n",
    "    / \"jigsaw-unintended-bias-in-toxicity-classification\"\n",
    "    / \"submission.csv\"\n",
    ")\n",
    "\n",
    "model_checkpoint = \"distilbert/distilbert-base-uncased\"\n",
    "num_epochs = 3\n",
    "learning_rate = 2e-5\n",
    "\n",
    "epoch_time = int(time.time())\n",
    "\n",
    "os.environ[\"PYTORCH_MPS_HIGH_WATERMARK_RATIO\"] = \"0.0\"\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "ds = load_toxicity_dataset(\n",
    "    EXTERNAL_DATA_FOLDER, PROCESSED_DATA_FOLDER, tokenizer, random_seed\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Prepare model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    num_labels=len(TOXICITY_LABEL_TO_ID),\n",
    "    id2label=TOXICITY_ID_TO_LABEL,\n",
    "    label2id=TOXICITY_LABEL_TO_ID,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=MODELS_FOLDER\n",
    "    / \"jigsaw-unintended-bias-in-toxicity-classification-checkpoint\",\n",
    "    learning_rate=learning_rate,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=num_epochs,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    seed=random_seed,\n",
    "    auto_find_batch_size=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    greater_is_better=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=ds[\"train\"],\n",
    "    eval_dataset=ds[\"test\"],\n",
    "    processing_class=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11281' max='11281' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11281/11281 03:14]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluation_feedback = trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.11260996013879776,\n",
       " 'eval_model_preparation_time': 0.0015,\n",
       " 'eval_precision': 0.8762262180281618,\n",
       " 'eval_recall': 0.8106681253394749,\n",
       " 'eval_f1': 0.8398366489224725,\n",
       " 'eval_runtime': 196.6295,\n",
       " 'eval_samples_per_second': 917.909,\n",
       " 'eval_steps_per_second': 57.372}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Save weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(MODELS_FOLDER / \"jigsaw-unintended-bias-in-toxicity-classification\")\n",
    "tokenizer.save_pretrained(\n",
    "    MODELS_FOLDER / \"jigsaw-unintended-bias-in-toxicity-classification\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Predict test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODELS_FOLDER / \"jigsaw-unintended-bias-in-toxicity-classification\"\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    MODELS_FOLDER / \"jigsaw-unintended-bias-in-toxicity-classification\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\n",
    "    EXTERNAL_DATA_FOLDER\n",
    "    / \"jigsaw-unintended-bias-in-toxicity-classification\"\n",
    "    / \"test.csv\"\n",
    ")\n",
    "submission = pd.read_csv(\n",
    "    EXTERNAL_DATA_FOLDER\n",
    "    / \"jigsaw-unintended-bias-in-toxicity-classification\"\n",
    "    / \"sample_submission.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = pipeline(\n",
    "    \"text-classification\", model=model, tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "prediction_df = pd.DataFrame.from_records(predictor(test[\"comment_text\"].values.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission[\"prediction\"] = prediction_df[\"label\"].map(TOXICITY_LABEL_TO_ID)\n",
    "\n",
    "submition_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "submission = submission.set_index(\"id\")\n",
    "\n",
    "submission.to_csv(submition_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = (\n",
    "    f\"[ {model_checkpoint} ] {num_epochs} epochs with {learning_rate} learning rate\"\n",
    ")\n",
    "\n",
    "submit_competition(submition_path, message, competition)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
